{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS246 - Colab 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPt5q27L5557",
        "colab_type": "text"
      },
      "source": [
        "# CS246 - Colab 1\n",
        "## Wordcount in Spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0-YhEpP_Ds-",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsj5WYpR9QId",
        "colab_type": "text"
      },
      "source": [
        "Let's setup Spark on your Colab environment.  Run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qHai2252mI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "9b525741-26d1-4f03-f8c2-e110aa588e23"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/b0/bf9020b56492281b9c9d8aae8f44ff51e1bc91b3ef5a884385cb4e389a40/pyspark-3.0.0.tar.gz (204.7MB)\n",
            "\u001b[K     |████████████████████████████████| 204.7MB 66kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 40.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044182 sha256=ac30a99309ce380f7e4aafcea38bfe4bb41691e68b32bf2116c48fad1def5fa3\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/27/4d/ddacf7143f8d5b76c45c61ee2e43d9f8492fc5a8e78ebd7d37\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.0\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 35.8 MB of archives.\n",
            "After this operation, 140 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJ71AKe91eh",
        "colab_type": "text"
      },
      "source": [
        "Now we authenticate a Google Drive client to download the file we will be processing in our Spark job.\n",
        "\n",
        "**Make sure to follow the interactive instructions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5K93ABEy9Zlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orRvrc1-545",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id='1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa'\n",
        "downloaded = drive.CreateFile({'id': id})\n",
        "downloaded.GetContentFile('pg100.txt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtlO4_m_LbQ",
        "colab_type": "text"
      },
      "source": [
        "If you executed the cells above, you should be able to see the file *pg100.txt* under the \"Files\" tab on the left panel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRaF2A_j_nC7",
        "colab_type": "text"
      },
      "source": [
        "### Your task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebLNUxP0_8x3",
        "colab_type": "text"
      },
      "source": [
        "If you run successfully the setup stage, you are ready to work on the *pg100.txt* file which contains a copy of the complete works of Shakespeare.\n",
        "\n",
        "Write a Spark application which outputs the number of words that start with each letter. This means that for every letter we want to count the total number of (non-unique) words that start with a specific letter. In your implementation **ignore the letter case**, i.e., consider all words as lower case. Also, you can ignore all the words **starting** with a non-alphabetic character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu-e7Ph2_ruG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "import pandas as pd\n",
        "\n",
        "# create the Spark Session\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# create the Spark Context\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuAxGFPFB43Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "66f0e86f-c593-4e43-fa82-54b01cc9f40d"
      },
      "source": [
        "# YOUR\n",
        "downloaded"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogleDriveFile({'id': '1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa', 'kind': 'drive#file', 'etag': '\"MTU3ODQ0MjAxNzc4OQ\"', 'selfLink': 'https://www.googleapis.com/drive/v2/files/1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa', 'webContentLink': 'https://drive.google.com/uc?id=1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa&export=download', 'alternateLink': 'https://drive.google.com/file/d/1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa/view?usp=drivesdk', 'embedLink': 'https://drive.google.com/file/d/1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa/preview?usp=drivesdk', 'iconLink': 'https://drive-thirdparty.googleusercontent.com/16/type/text/plain', 'thumbnailLink': 'https://lh3.googleusercontent.com/cizOyQrlCsbhouOOjXYJjSAVFlO23FThx7nt0X9PJi62trQjvarLV0yReptTioKo3MuQ7XVxx7w=s220', 'title': 'pg100.txt', 'mimeType': 'text/plain', 'labels': {'starred': False, 'hidden': False, 'trashed': False, 'restricted': False, 'viewed': False}, 'copyRequiresWriterPermission': False, 'createdDate': '2020-01-08T00:04:41.233Z', 'modifiedDate': '2020-01-08T00:06:57.789Z', 'markedViewedByMeDate': '1970-01-01T00:00:00.000Z', 'version': '25', 'parents': [], 'downloadUrl': 'https://www.googleapis.com/drive/v2/files/1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa?alt=media&source=downloadUrl', 'userPermission': {'kind': 'drive#permission', 'etag': '\"kyD7UUp_dMsAD0VQ4BKkcrKx17c\"', 'id': 'me', 'selfLink': 'https://www.googleapis.com/drive/v2/files/1SE6k_0YukzGd5wK-E4i6mG83nydlfvSa/permissions/me', 'role': 'reader', 'type': 'user'}, 'originalFilename': 'pg100.txt', 'fileExtension': 'txt', 'md5Checksum': 'a810f89e9f8e213aebd06b9f8c5157d8', 'fileSize': '5589889', 'quotaBytesUsed': '0', 'ownerNames': ['Michele Catasta'], 'owners': [{'kind': 'drive#user', 'displayName': 'Michele Catasta', 'picture': {'url': 'https://lh3.googleusercontent.com/a-/AOh14GhLboQ4M3ViHTXMiE_OVrXXn03YYgZXwP3cRV5bRg=s64'}, 'isAuthenticatedUser': False, 'permissionId': '12873656845038060184', 'emailAddress': 'pirroh@gmail.com'}], 'lastModifyingUserName': 'Michele Catasta', 'lastModifyingUser': {'kind': 'drive#user', 'displayName': 'Michele Catasta', 'picture': {'url': 'https://lh3.googleusercontent.com/a-/AOh14GhLboQ4M3ViHTXMiE_OVrXXn03YYgZXwP3cRV5bRg=s64'}, 'isAuthenticatedUser': False, 'permissionId': '12873656845038060184', 'emailAddress': 'pirroh@gmail.com'}, 'capabilities': {'canCopy': True, 'canEdit': False}, 'editable': False, 'copyable': True, 'writersCanShare': True, 'shared': True, 'explicitlyTrashed': False, 'appDataContents': False, 'headRevisionId': '0B4aIvUjhDV8XbGo4Z0x1bW5DR0dmS0lPMWR3a2JRNGUyM1Y4PQ', 'spaces': ['drive']})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DcgP8qsZzSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "894c985f-8fac-464b-f38c-67401c4a3a16"
      },
      "source": [
        "# read in the text file and make it an RDD\n",
        "data = sc.textFile('pg100.txt')\n",
        "\n",
        "# split the data with a space. Since we are only counting the first letter of each word, further processing is not necessary\n",
        "data = data.flatMap(lambda line: line.strip().split(' '))\n",
        "\n",
        "# construct the key-value pairs\n",
        "data = data.map(lambda word: (word[0].lower(), 1) if word and word[0].isalpha() else (None,0))\n",
        "\n",
        "data.take(20)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('t', 1),\n",
              " ('p', 1),\n",
              " ('g', 1),\n",
              " ('e', 1),\n",
              " ('o', 1),\n",
              " ('t', 1),\n",
              " ('c', 1),\n",
              " ('w', 1),\n",
              " ('o', 1),\n",
              " ('w', 1),\n",
              " ('s', 1),\n",
              " ('b', 1),\n",
              " ('w', 1),\n",
              " ('s', 1),\n",
              " (None, 0),\n",
              " ('t', 1),\n",
              " ('e', 1),\n",
              " ('i', 1),\n",
              " ('f', 1),\n",
              " ('t', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-SSxDs9FdJa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "3bbe77d2-d070-4855-95c3-2d81ef8995ed"
      },
      "source": [
        "# Sum the counters in the reduce step, and sort by count\n",
        "data = data.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# show the 10 frequent words\n",
        "data.filter(lambda x: x[1] > 0).sortBy(lambda x: x[0]).collect()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 84836),\n",
              " ('b', 45455),\n",
              " ('c', 34567),\n",
              " ('d', 29713),\n",
              " ('e', 18697),\n",
              " ('f', 36814),\n",
              " ('g', 20782),\n",
              " ('h', 60563),\n",
              " ('i', 62167),\n",
              " ('j', 3339),\n",
              " ('k', 9418),\n",
              " ('l', 29569),\n",
              " ('m', 55676),\n",
              " ('n', 26759),\n",
              " ('o', 43494),\n",
              " ('p', 27759),\n",
              " ('q', 2377),\n",
              " ('r', 14265),\n",
              " ('s', 65705),\n",
              " ('t', 123602),\n",
              " ('u', 9170),\n",
              " ('v', 5728),\n",
              " ('w', 59597),\n",
              " ('x', 14),\n",
              " ('y', 25855),\n",
              " ('z', 71)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLuEe0jGeqL3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIrXJyVNP2AI",
        "colab_type": "text"
      },
      "source": [
        "Once you obtained the desired results, **head over to Gradescope and submit your solution for this Colab**!"
      ]
    }
  ]
}