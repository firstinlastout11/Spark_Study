{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPt5q27L5557"
   },
   "source": [
    "# CS246 - Colab 4\n",
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0-YhEpP_Ds-"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zsj5WYpR9QId"
   },
   "source": [
    "Let's setup Spark on your Colab environment.  Run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "colab_type": "code",
    "id": "k-qHai2252mI",
    "outputId": "ab4a3c06-11b5-4674-89fb-c5e23d7733bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/b0/bf9020b56492281b9c9d8aae8f44ff51e1bc91b3ef5a884385cb4e389a40/pyspark-3.0.0.tar.gz (204.7MB)\n",
      "\u001b[K     |████████████████████████████████| 204.7MB 63kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.9\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 42.7MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044182 sha256=61056ea18f5078bd15174a736ad05ab61f919c17dc2f694e010586ea96ba6adc\n",
      "  Stored in directory: /root/.cache/pip/wheels/57/27/4d/ddacf7143f8d5b76c45c61ee2e43d9f8492fc5a8e78ebd7d37\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9 pyspark-3.0.0\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  openjdk-8-jre-headless\n",
      "Suggested packages:\n",
      "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  fonts-wqy-zenhei fonts-indic\n",
      "The following NEW packages will be installed:\n",
      "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
      "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 35.8 MB of archives.\n",
      "After this operation, 140 MB of additional disk space will be used.\n",
      "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
      "(Reading database ... 144465 files and directories currently installed.)\n",
      "Preparing to unpack .../openjdk-8-jre-headless_8u252-b09-1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
      "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
      "Preparing to unpack .../openjdk-8-jdk-headless_8u252-b09-1~18.04_amd64.deb ...\n",
      "Unpacking openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
      "Setting up openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
      "Setting up openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install -U -q PyDrive\n",
    "!apt install openjdk-8-jdk-headless -qq\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PUUjUvXe3Sjk"
   },
   "source": [
    "Now we authenticate a Google Drive client to download the filea we will be processing in our Spark job.\n",
    "\n",
    "**Make sure to follow the interactive instructions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRElWs_x2mGh"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QHsFTGUy2n1c"
   },
   "outputs": [],
   "source": [
    "id='1QtPy_HuIMSzhtYllT3-WeM3Sqg55wK_D'\n",
    "downloaded = drive.CreateFile({'id': id})\n",
    "downloaded.GetContentFile('MovieLens.training')\n",
    "\n",
    "id='1ePqnsQTJRRvQcBoF2EhoPU8CU1i5byHK'\n",
    "downloaded = drive.CreateFile({'id': id})\n",
    "downloaded.GetContentFile('MovieLens.test')\n",
    "\n",
    "id='1ncUBWdI5AIt3FDUJokbMqpHD2knd5ebp'\n",
    "downloaded = drive.CreateFile({'id': id})\n",
    "downloaded.GetContentFile('MovieLens.item')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qwtlO4_m_LbQ"
   },
   "source": [
    "If you executed the cells above, you should be able to see the dataset we will use for this Colab under the \"Files\" tab on the left panel.\n",
    "\n",
    "Next, we import some of the common libraries needed for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cfb_a0lufpkO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtrJlMBt1Ela"
   },
   "source": [
    "Let's initialize the Spark context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ziTX4ts0f0fQ"
   },
   "outputs": [],
   "source": [
    "# create the session\n",
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "\n",
    "# create the context\n",
    "sc = pyspark.SparkContext(conf = conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqovskkH1DmC"
   },
   "source": [
    "You can easily check the current version and get the link of the web interface. In the Spark UI, you can monitor the progress of your job and debug the performance bottlenecks (if your Colab is running with a **local runtime**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "DueQggJc1DDk",
    "outputId": "abfdd054-6898-4dfc-e665-fee2931d90e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://69e1b6a78e27:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fed3499a8d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iid7lXcG1CY8"
   },
   "source": [
    "If you are running this Colab on the Google hosted runtime, the cell below will create a *ngrok* tunnel which will allow you to still check the Spark UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "sDnGLVPH1BPQ",
    "outputId": "21f0d901-2981-4931-cdb5-2b8ff584f4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-07-31 07:10:04--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 34.195.187.253, 54.161.19.10, 35.175.20.97, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|34.195.187.253|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13773305 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "\r",
      "          ngrok-sta   0%[                    ]       0  --.-KB/s               \r",
      "         ngrok-stab  76%[==============>     ]  10.07M  50.1MB/s               \r",
      "ngrok-stable-linux- 100%[===================>]  13.13M  57.9MB/s    in 0.2s    \n",
      "\n",
      "2020-07-31 07:10:05 (57.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
      "\n",
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n",
      "http://bf87e22cce96.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "get_ipython().system_raw('./ngrok http 4050 &')\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kAYRX2PMm0L6"
   },
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hXdMR6wnEIM"
   },
   "source": [
    "In this Colab, we will be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/), specifically the 100K dataset (which contains in total 100,000 ratings from 1000 users on ~1700 movies).\n",
    "\n",
    "We load the ratings data in a 80%-20% ```training```/```test``` split, while the ```items``` dataframe contains the movie titles associated to the item identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5K93ABEy9Zlo"
   },
   "outputs": [],
   "source": [
    "schema_ratings = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), False),\n",
    "    StructField(\"item_id\", IntegerType(), False),\n",
    "    StructField(\"rating\", IntegerType(), False),\n",
    "    StructField(\"timestamp\", IntegerType(), False)])\n",
    "\n",
    "schema_items = StructType([\n",
    "    StructField(\"item_id\", IntegerType(), False),\n",
    "    StructField(\"movie\", StringType(), False)])\n",
    "\n",
    "training = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.training\", header=False, schema=schema_ratings)\n",
    "test = spark.read.option(\"sep\", \"\\t\").csv(\"MovieLens.test\", header=False, schema=schema_ratings)\n",
    "items = spark.read.option(\"sep\", \"|\").csv(\"MovieLens.item\", header=False, schema=schema_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "MC_m1oygCoEm",
    "outputId": "3fc66bd6-ec0e-4854-d057-5fd0e1e717fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "81Vgo4ovCqtQ",
    "outputId": "3eca725b-e142-4a46-8108-a5414032e47f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- movie: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CRaF2A_j_nC7"
   },
   "source": [
    "### Your task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zM9w2aUvJ7KN"
   },
   "source": [
    "Let's compute some stats!  What is the number of ratings in the training and test dataset? How many movies are in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8XZaH16t_CIw",
    "outputId": "57951d37-b95f-4c4a-91a4-1b9e69807834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 80000 ratings in the training dataset\n",
      "There are a total of 20000 ratings in the test dataset\n",
      "There are a total of 1682 movies in the dataset\n"
     ]
    }
   ],
   "source": [
    "# To compute the number of ratings in the training, test dataset\n",
    "print(f\"There are a total of {training.count()} ratings in the training dataset\")\n",
    "print(f\"There are a total of {test.count()} ratings in the test dataset\")\n",
    "print(f\"There are a total of {items.count()} movies in the dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpsaYOqRxar2"
   },
   "source": [
    "Using the training set, train a model with the Alternating Least Squares method available in the Spark MLlib: [https://spark.apache.org/docs/latest/ml-collaborative-filtering.html](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oitav_xhQD9w"
   },
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(rank = 10, maxIter = 10, regParam = 0.05, userCol = 'user_id', itemCol = 'item_id', ratingCol = 'rating', coldStartStrategy = 'drop')\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TtR1xRvonxiO"
   },
   "source": [
    "Now compute the RMSE on the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GP23Xkgwi0SD",
    "outputId": "f477f774-31d8-45f1-a0b8-4e9fe9bb795d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9772023825075241\n"
     ]
    }
   ],
   "source": [
    "# predict the ratings on the test set\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# perfrom the model evaluation using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol = 'rating', predictionCol = 'prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UkmRMdMv2lrx",
    "outputId": "987b9ec4-dca6-4883-8fb4-6bf1c5ed6530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.959792733047571\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(rank = 5, maxIter = 10, regParam = 0.05, userCol = 'user_id', itemCol = 'item_id', ratingCol = 'rating', coldStartStrategy = 'drop')\n",
    "model = als.fit(training)\n",
    "\n",
    "# predict the ratings on the test set\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# perfrom the model evaluation using RMSE\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol = 'rating', predictionCol = 'prediction')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "YhoZTn562jb8",
    "outputId": "6a4feb80-9829-4187-f9e7-a755e2ad5cca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 1.0257683298171587 when reg is 0.01\n",
      "Root-mean-square error = 0.959792733047571 when reg is 0.05\n",
      "Root-mean-square error = 0.9334998580325293 when reg is 0.1\n",
      "Root-mean-square error = 1.0742546999109326 when reg is 0.5\n"
     ]
    }
   ],
   "source": [
    "reg_list = [0.01, 0.05, 0.1, 0.5]\n",
    "for reg in reg_list:\n",
    "\n",
    "  # Build the recommendation model using ALS on the training data\n",
    "  als = ALS(rank = 5, maxIter = 10, regParam = reg, userCol = 'user_id', itemCol = 'item_id', ratingCol = 'rating', coldStartStrategy = 'drop')\n",
    "  model = als.fit(training)\n",
    "\n",
    "  # predict the ratings on the test set\n",
    "  predictions = model.transform(test)\n",
    "\n",
    "  # perfrom the model evaluation using RMSE\n",
    "  evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol = 'rating', predictionCol = 'prediction')\n",
    "  rmse = evaluator.evaluate(predictions)\n",
    "  print(\"Root-mean-square error = \" + str(rmse) +\" when reg is \" + str(reg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lBvSaWGEMHXI"
   },
   "source": [
    "At this point, you can use the trained model to produce the top-K recommendations for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KbMlWL5_UfSc",
    "outputId": "fa032c63-09cf-45b0-9c14-29080d18367a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, recommendations: array<struct<item_id:int,rating:float>>]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# produce the top-10 recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "\n",
    "# produce the top-10 user recommendations for each movie\n",
    "movieRecs = model.recommendForAllItems(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "8WwDASsRpAdL",
    "outputId": "0ac742a4-a1b2-4994-9049-5ea9cd35331e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=471, recommendations=[Row(item_id=962, rating=8.115094184875488), Row(item_id=1167, rating=7.527532577514648), Row(item_id=1207, rating=6.686556339263916), Row(item_id=1155, rating=6.375487327575684), Row(item_id=40, rating=6.283472537994385), Row(item_id=1152, rating=6.275321960449219), Row(item_id=1217, rating=6.259552001953125), Row(item_id=1278, rating=6.231823921203613), Row(item_id=1615, rating=6.2159810066223145), Row(item_id=944, rating=6.018719673156738)]),\n",
       " Row(user_id=463, recommendations=[Row(item_id=851, rating=4.9817352294921875), Row(item_id=867, rating=4.9796624183654785), Row(item_id=1643, rating=4.9398112297058105), Row(item_id=916, rating=4.92707633972168), Row(item_id=909, rating=4.909367561340332), Row(item_id=793, rating=4.890866279602051), Row(item_id=1449, rating=4.838788986206055), Row(item_id=1512, rating=4.8054070472717285), Row(item_id=516, rating=4.7797112464904785), Row(item_id=408, rating=4.715842247009277)]),\n",
       " Row(user_id=833, recommendations=[Row(item_id=1288, rating=5.040386199951172), Row(item_id=589, rating=5.038176536560059), Row(item_id=253, rating=4.984405040740967), Row(item_id=902, rating=4.859286785125732), Row(item_id=995, rating=4.820207595825195), Row(item_id=1187, rating=4.791012763977051), Row(item_id=896, rating=4.78671407699585), Row(item_id=1597, rating=4.738706588745117), Row(item_id=1388, rating=4.6324028968811035), Row(item_id=160, rating=4.625272750854492)]),\n",
       " Row(user_id=496, recommendations=[Row(item_id=1240, rating=5.212222099304199), Row(item_id=1113, rating=5.161056995391846), Row(item_id=1001, rating=5.087285995483398), Row(item_id=922, rating=5.073411464691162), Row(item_id=613, rating=5.057503700256348), Row(item_id=787, rating=4.970182418823242), Row(item_id=902, rating=4.893851280212402), Row(item_id=1015, rating=4.8249921798706055), Row(item_id=952, rating=4.822704792022705), Row(item_id=1077, rating=4.81144380569458)]),\n",
       " Row(user_id=148, recommendations=[Row(item_id=1019, rating=6.868131637573242), Row(item_id=115, rating=6.569283485412598), Row(item_id=624, rating=6.292964458465576), Row(item_id=1268, rating=6.01544713973999), Row(item_id=774, rating=5.781144142150879), Row(item_id=1220, rating=5.748445510864258), Row(item_id=1113, rating=5.74775505065918), Row(item_id=1496, rating=5.712822437286377), Row(item_id=1077, rating=5.636508464813232), Row(item_id=943, rating=5.617660045623779)])]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userRecs.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "59hfFdtG42kf",
    "outputId": "f6d7aa73-2cd2-48ea-a2b0-d9d93a5da595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id=471, movie_recommendation='Ruby in Paradise (1993)'),\n",
       " Row(user_id=463, movie_recommendation='Two or Three Things I Know About Her (1966)'),\n",
       " Row(user_id=833, movie_recommendation='Denise Calls Up (1995)'),\n",
       " Row(user_id=496, movie_recommendation='Ghost in the Shell (Kokaku kidotai) (1995)'),\n",
       " Row(user_id=148, movie_recommendation='Die xue shuang xiong (Killer, The) (1989)'),\n",
       " Row(user_id=540, movie_recommendation='Safe (1995)'),\n",
       " Row(user_id=392, movie_recommendation='Angel Baby (1995)'),\n",
       " Row(user_id=243, movie_recommendation='Angel Baby (1995)'),\n",
       " Row(user_id=623, movie_recommendation='Angel Baby (1995)'),\n",
       " Row(user_id=737, movie_recommendation='Mina Tannenbaum (1994)')]"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the top 1 recommendations\n",
    "userRecs_new = userRecs.select('user_id', expr(\"recommendations['item_id']\")[0].alias('item_id'))\n",
    "\n",
    "# join the table with the item table\n",
    "userRecs_new.join(items, userRecs_new.item_id == items.item_id).select(col('user_id'),col('movie').alias(\"movie_recommendation\")).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SIrXJyVNP2AI"
   },
   "source": [
    "Once you have working code for each cell above, **head over to Gradescope, read carefully the questions, and submit your solution for this Colab**!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CS246 - Colab 4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
